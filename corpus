#!/usr/bin/env ruby
require 'feature_scorer'
require 'cue_wrapper' if RUBY_PLATFORM == 'java'
require 'thor'
require 'zip/zip'
require 'thread/pool'
require 'yaml'
require 'base64'

class AnalysisHelper
  def initialize(analysis)
    @analysis = analysis
  end

  def literals
    @analysis.entry.token_interpretations.map { |ti| ti.text.downcase }
  end

  def concepts
    @analysis.entry.token_interpretations.flat_map { |ti| ti.concepts.map { |c| c.to_s } }
  end

  def ocfs
    @analysis.entry.token_interpretations.flat_map { |ti| ti.orthographically_correct.map { |ocf| ocf.text } }
  end

  def features
    concepts.map { |c| {text: c, type: :concept} } +
        ocfs.map { |ocf| {text: ocf, type: :ocf} } +
        literals.map { |l| {text: l, type: :literal} }
  end
end

class ScoreExporter

  def initialize(evaluator, output_file)
    @evaluator = evaluator
    @output_file = output_file
  end

  def open
    @file = File.open(@output_file, 'w')
  end

  def close
    @file.close if @file
  end

  def write_header
    @file.puts 'Feature|Type|Score|Tag|N11|N10|N01|N00|Uniq x Doc|Freq Abs Tag|Freq Abs No Tag'
  end

  def write(feature, corpus)
    @evaluator.evaluate(feature, corpus).each do |evaluation|
      m = corpus.feature_summaries[feature][evaluation.tag]
      @file.puts "\"#{evaluation.feature.text}\"|#{evaluation.feature.type}|#{evaluation.score}|#{evaluation.tag}|#{m.n11}|#{m.n10}|#{m.n01}|#{m.n00}|#{m.n1_}|#{m.specific_occurrences}|#{m.residue_occurrences}"
    end
  end

end

class Corpus < Thor

  desc 'create', 'Create corpus from CSV file [text, tag]'
  method_option :rows, type: :numeric, aliases: '-r', desc: 'Rows limit'
  method_option :threads, type: :numeric, aliases: '-t', desc: 'Thread pool size'

  def create(csv_file)
    puts "Creating corpus from #{csv_file}"
    tmp_path = "/tmp/#{Time.now.to_i}"
    basename = File.basename(csv_file, '.*')
    path = "#{tmp_path}/#{basename}"

    FileUtils.mkpath path

    csv = File.open(csv_file, 'r') { |f| f.readlines }
    rows_limit = options[:rows] || (csv.count - 1)
    rows_processed = 0

    cue = CueWrapper::Cue.new language: :english
    runner = cue.send :cue

    pool = Thread::Pool.new(options[:threads])
    mutex = Mutex.new

    start = Time.now
    1.upto(rows_limit) do |i|
      pool.process do
        text, tag = csv[i].split('|')
        puts "Analyzing #{i}/#{rows_limit}: #{text[0..60]}"
        analysis = AnalysisHelper.new(runner.run(cue.send(:request, text)))
        features = analysis.features.map { |f| FeatureScorer::Feature.new(f[:text], f[:type]) }
        File.open("#{path}/#{i}.bin", 'w') { |f| f.write serialize(FeatureScorer::Document.new(features, tag.strip)) }
        mutex.synchronize { rows_processed += 1 }
        puts "Complete #{rows_processed}/#{rows_limit}: #{text[0..60]}"
      end
    end

    loop do
      break if rows_processed == rows_limit
    end
    finish = Time.now

    pool.shutdown

    zip path, "#{basename}_#{rows_limit}rows.corpus"

    FileUtils.rm_rf tmp_path
    puts "Time: #{finish - start}"
  end

  desc 'scores', 'Calculate scores for corpus file'
  method_option :path, aliases: '-p', desc: 'Path where puts output files'

  def scores(corpus_file)
    start = Time.now
    corpus = load_corpus(corpus_file)

    puts "Detected tags: #{corpus.tags.join(', ')}"
    if corpus.tags.count < 2
      puts "Can't calculate feature selection if corpus has less than two tags"
      return
    end

    path = options[:path] || "#{File.basename(corpus_file, '.*')}_#{Time.now.to_i}"
    FileUtils.rm_rf path if Dir.exists?(path)
    FileUtils.mkpath path

    puts 'Calculating scores'
    exporters = [
        ScoreExporter.new(FeatureScorer::MutualInformationEvaluator.new, "#{path}/mi_scores.csv"),
        ScoreExporter.new(FeatureScorer::ChiSquareEvaluator.new, "#{path}/chi_scores.csv"),
        ScoreExporter.new(FeatureScorer::TfIdfEvaluator.new, "#{path}/tf_idf_scores.csv"),
        ScoreExporter.new(FeatureScorer::PlainFrequencyEvaluator.new, "#{path}/plain_scores.csv")
    ]

    exporters.each do |e|
      e.open
      e.write_header
    end

    i = 0
    uniq_features = corpus.features.uniq
    uniq_features.each do |feature|
      puts "Processing feature (#{i+=1}/#{uniq_features.count}): #{feature}"
      exporters.each { |e| e.write feature, corpus }
    end

    exporters.each { |e| e.close }

    puts 'Processing summary info'
    File.open("#{path}/info.txt", 'w') do |f|
      f.puts 'Tags:'
      corpus.tag_distribution.each do |tag, count|
        f.puts "- #{tag}: #{count}"
      end

      f.puts "Documents: #{corpus.count}"
      f.puts "Low limit frequency: #{corpus.low_frequency_limit}"

      uniq_features = corpus.features.uniq
      f.puts 'Features (uniq):'
      f.puts "- Literal: #{uniq_features.select { |f| f.type == :literal }.count}"
      f.puts "- Concept: #{uniq_features.select { |f| f.type == :concept }.count}"
      f.puts "- OCF: #{uniq_features.select { |f| f.type == :ocf }.count}"

      tokens_count = corpus.features.select { |f| f.type == :literal }.count
      f.puts "Tokens: #{tokens_count}"
      f.puts "Token Avg: #{tokens_count/corpus.count}"

      f.puts 'Histogram:'
      histogram(corpus).each do |k, v|
        f.puts "- #{k} tokens: #{v} documents"
      end
    end

    puts "Time: #{Time.now - start}"
  end

  private

  def zip(folder, zip_file)
    puts 'Compressing corpus'
    File.delete zip_file if File.exists?(zip_file)
    Zip::ZipFile.open(zip_file, Zip::ZipFile::CREATE) do |zip|
      Dir.glob("#{folder}/*.*").each do |f|
        puts " - #{f}"
        zip.add(File.basename(f), f)
      end
    end
  end

  def load_corpus(corpus_file)
    corpus = nil
    Zip::ZipFile.open(corpus_file, Zip::ZipFile::CREATE) do |zip|
      puts 'Loading corpus'
      i = 0
      count = zip.entries.count
      documents = zip.entries.map do |f|
        puts "Parsing (#{i+=1}/#{count}): #{f.name}"
        File.extname(f.name) == '.bin' ? deserialize(zip.read(f.name)) : YAML.load(zip.read(f.name))
      end
      corpus = FeatureScorer::Corpus.new(documents)
    end
    corpus
  end

  def histogram(corpus)
    documents = corpus.map { |d| d.features.select { |f| f.type == :literal }.count }.sort

    slot = ((documents.last - documents.first).to_f / 10).round(1)

    previous = documents.first

    1.upto(10).inject({}) do |hash, i|
      current = (previous + slot).round(1)
      hash["#{previous.to_i} to #{current.to_i}"] = documents.select { |n| n >= previous && n < current }.count
      hash["#{previous.to_i} to #{current.to_i}"] += 1 if i == 10
      previous = current
      hash
    end
  end

  def serialize(object)
    Base64.encode64(Marshal.dump(object))
  end

  def deserialize(string)
    Marshal.load(Base64.decode64(string))
  end

end

Corpus.start